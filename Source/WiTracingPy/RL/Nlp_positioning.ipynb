{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from WIreless_encoder.TXDataset import TXDataset\n",
    "from WIreless_encoder.model import WirelessEncoder\n",
    "import torch\n",
    "\n",
    "img = cv2.imread('map/map_wireframe.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\liuxi/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "# Define the tokenizer\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuxi\\Git Repo\\WirelessDT\\Source\\WiTracingPy\\RL\\WIreless_encoder\\TXDataset.py:16: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  self.data = self.data.groupby(['timestamp', 'x', 'y', 'z'])['rssi', 'tx'].agg(tolist).reset_index()\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# Create the dataset and dataloader\n",
    "\n",
    "# Custom collate function for padding sequences\n",
    "def custom_collate(batch):\n",
    "    # Separate the input data (txnames) and labels\n",
    "    txnames = [item[0] for item in batch]\n",
    "    labels = torch.tensor([item[1] for item in batch])\n",
    "\n",
    "    # Pad the sequences in txnames using pad_sequence\n",
    "    padded_txnames = pad_sequence(txnames, batch_first=True)\n",
    "\n",
    "    # Return the padded input data and labels\n",
    "    return padded_txnames, labels\n",
    "\n",
    "dataset = TXDataset('raw.csv', tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=custom_collate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "          timestamp           x            y           z  \\\n0     1679538902693  475.289673  1482.590576  102.184547   \n1     1679538902759  476.011902  1483.588623  110.404449   \n2     1679538902794  486.526764  1481.530273  110.504608   \n3     1679538902828  496.901855  1474.441528  110.863770   \n4     1679538902860  506.555115  1461.993652  111.978073   \n...             ...         ...          ...         ...   \n6292  1679539160779 -693.878540  7103.696777  114.846436   \n6293  1679539160804 -693.678711  7106.986816  114.070290   \n6294  1679539160831 -693.429626  7110.733398  113.161743   \n6295  1679539160858 -693.255554  7114.434570  112.097168   \n6296  1679539160884 -693.239624  7117.571289  111.003342   \n\n                                     rssi  \\\n0          [-58, -70, -67, -66, -62, -58]   \n1          [-57, -72, -67, -67, -63, -58]   \n2          [-57, -69, -65, -65, -64, -59]   \n3          [-57, -71, -66, -67, -63, -60]   \n4          [-57, -70, -67, -66, -62, -60]   \n...                                   ...   \n6292  [-74, -73, -61, -65, -55, -58, -64]   \n6293  [-73, -74, -62, -65, -54, -58, -64]   \n6294  [-73, -75, -61, -65, -54, -58, -64]   \n6295  [-73, -74, -62, -65, -54, -58, -64]   \n6296  [-74, -75, -61, -66, -54, -58, -64]   \n\n                                                     tx  \n0     [TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...  \n1     [TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...  \n2     [TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...  \n3     [TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...  \n4     [TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...  \n...                                                 ...  \n6292  [TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...  \n6293  [TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...  \n6294  [TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...  \n6295  [TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...  \n6296  [TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...  \n\n[6297 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>rssi</th>\n      <th>tx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1679538902693</td>\n      <td>475.289673</td>\n      <td>1482.590576</td>\n      <td>102.184547</td>\n      <td>[-58, -70, -67, -66, -62, -58]</td>\n      <td>[TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1679538902759</td>\n      <td>476.011902</td>\n      <td>1483.588623</td>\n      <td>110.404449</td>\n      <td>[-57, -72, -67, -67, -63, -58]</td>\n      <td>[TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1679538902794</td>\n      <td>486.526764</td>\n      <td>1481.530273</td>\n      <td>110.504608</td>\n      <td>[-57, -69, -65, -65, -64, -59]</td>\n      <td>[TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1679538902828</td>\n      <td>496.901855</td>\n      <td>1474.441528</td>\n      <td>110.863770</td>\n      <td>[-57, -71, -66, -67, -63, -60]</td>\n      <td>[TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1679538902860</td>\n      <td>506.555115</td>\n      <td>1461.993652</td>\n      <td>111.978073</td>\n      <td>[-57, -70, -67, -66, -62, -60]</td>\n      <td>[TX_F1_Fountain, TX_F1_Instrument_4, TX_F1_Ins...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6292</th>\n      <td>1679539160779</td>\n      <td>-693.878540</td>\n      <td>7103.696777</td>\n      <td>114.846436</td>\n      <td>[-74, -73, -61, -65, -55, -58, -64]</td>\n      <td>[TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...</td>\n    </tr>\n    <tr>\n      <th>6293</th>\n      <td>1679539160804</td>\n      <td>-693.678711</td>\n      <td>7106.986816</td>\n      <td>114.070290</td>\n      <td>[-73, -74, -62, -65, -54, -58, -64]</td>\n      <td>[TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...</td>\n    </tr>\n    <tr>\n      <th>6294</th>\n      <td>1679539160831</td>\n      <td>-693.429626</td>\n      <td>7110.733398</td>\n      <td>113.161743</td>\n      <td>[-73, -75, -61, -65, -54, -58, -64]</td>\n      <td>[TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...</td>\n    </tr>\n    <tr>\n      <th>6295</th>\n      <td>1679539160858</td>\n      <td>-693.255554</td>\n      <td>7114.434570</td>\n      <td>112.097168</td>\n      <td>[-73, -74, -62, -65, -54, -58, -64]</td>\n      <td>[TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...</td>\n    </tr>\n    <tr>\n      <th>6296</th>\n      <td>1679539160884</td>\n      <td>-693.239624</td>\n      <td>7117.571289</td>\n      <td>111.003342</td>\n      <td>[-74, -75, -61, -66, -54, -58, -64]</td>\n      <td>[TX_F1_DressCode_17, TX_F1_DressCode_18, TX_F1...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6297 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create a neural network instance with 1000 possible words in the vocabulary, 16 embedding dimensions, and a hidden size of 64\n",
    "model = WirelessEncoder(num_words=tokenizer.vocab_size, embedding_dim=16, hidden_size=64).to(\"cuda\")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 44212.467\n",
      "Epoch 2, loss: 53092.647\n",
      "Epoch 3, loss: 43576.357\n",
      "Epoch 4, loss: 53231.727\n",
      "Epoch 5, loss: 46371.064\n",
      "Epoch 6, loss: 46942.244\n",
      "Epoch 7, loss: 47976.798\n",
      "Epoch 8, loss: 48082.109\n",
      "Epoch 9, loss: 44200.282\n",
      "Epoch 10, loss: 39892.449\n",
      "Epoch 11, loss: 20941.595\n",
      "Epoch 12, loss: 10889.954\n",
      "Epoch 13, loss: 9906.260\n",
      "Epoch 14, loss: 9695.322\n",
      "Epoch 15, loss: 9972.127\n",
      "Epoch 16, loss: 9708.783\n",
      "Epoch 17, loss: 9469.646\n",
      "Epoch 18, loss: 8894.904\n",
      "Epoch 19, loss: 8542.601\n",
      "Epoch 20, loss: 8445.325\n",
      "Epoch 21, loss: 8444.957\n",
      "Epoch 22, loss: 8375.381\n",
      "Epoch 23, loss: 8324.323\n",
      "Epoch 24, loss: 8268.936\n",
      "Epoch 25, loss: 8221.993\n",
      "Epoch 26, loss: 8159.649\n",
      "Epoch 27, loss: 8108.817\n",
      "Epoch 28, loss: 8036.282\n",
      "Epoch 29, loss: 7975.452\n",
      "Epoch 30, loss: 7892.875\n",
      "Epoch 31, loss: 7816.675\n",
      "Epoch 32, loss: 7701.143\n",
      "Epoch 33, loss: 7601.132\n",
      "Epoch 34, loss: 7473.079\n",
      "Epoch 35, loss: 7335.505\n",
      "Epoch 36, loss: 7119.005\n",
      "Epoch 37, loss: 7892.846\n",
      "Epoch 38, loss: 6122.812\n",
      "Epoch 39, loss: 4175.956\n",
      "Epoch 40, loss: 3840.050\n",
      "Epoch 41, loss: 2492.991\n",
      "Epoch 42, loss: 2520.748\n",
      "Epoch 43, loss: 2319.189\n",
      "Epoch 44, loss: 2068.187\n",
      "Epoch 45, loss: 1809.024\n",
      "Epoch 46, loss: 1563.008\n",
      "Epoch 47, loss: 1559.223\n",
      "Epoch 48, loss: 1341.059\n",
      "Epoch 49, loss: 1163.694\n",
      "Epoch 50, loss: 1052.881\n",
      "Epoch 51, loss: 1250.818\n",
      "Epoch 52, loss: 1272.413\n",
      "Epoch 53, loss: 1212.359\n",
      "Epoch 54, loss: 863.819\n",
      "Epoch 55, loss: 1632.292\n",
      "Epoch 56, loss: 996.999\n",
      "Epoch 57, loss: 878.042\n",
      "Epoch 58, loss: 1413.092\n",
      "Epoch 59, loss: 851.827\n",
      "Epoch 60, loss: 645.633\n",
      "Epoch 61, loss: 758.182\n",
      "Epoch 62, loss: 753.497\n",
      "Epoch 63, loss: 609.979\n",
      "Epoch 64, loss: 565.895\n",
      "Epoch 65, loss: 555.402\n",
      "Epoch 66, loss: 662.207\n",
      "Epoch 67, loss: 595.020\n",
      "Epoch 68, loss: 491.810\n",
      "Epoch 69, loss: 534.820\n",
      "Epoch 70, loss: 530.637\n",
      "Epoch 71, loss: 1208.974\n",
      "Epoch 72, loss: 1494.428\n",
      "Epoch 73, loss: 630.960\n",
      "Epoch 74, loss: 476.830\n",
      "Epoch 75, loss: 554.322\n",
      "Epoch 76, loss: 485.817\n",
      "Epoch 77, loss: 454.619\n",
      "Epoch 78, loss: 430.763\n",
      "Epoch 79, loss: 437.871\n",
      "Epoch 80, loss: 387.426\n",
      "Epoch 81, loss: 377.022\n",
      "Epoch 82, loss: 411.584\n",
      "Epoch 83, loss: 469.516\n",
      "Epoch 84, loss: 467.374\n",
      "Epoch 85, loss: 794.059\n",
      "Epoch 86, loss: 500.819\n",
      "Epoch 87, loss: 572.947\n",
      "Epoch 88, loss: 562.370\n",
      "Epoch 89, loss: 517.685\n",
      "Epoch 90, loss: 504.725\n",
      "Epoch 91, loss: 487.210\n",
      "Epoch 92, loss: 422.206\n",
      "Epoch 93, loss: 436.119\n",
      "Epoch 94, loss: 400.964\n",
      "Epoch 95, loss: 437.571\n",
      "Epoch 96, loss: 535.471\n",
      "Epoch 97, loss: 561.276\n",
      "Epoch 98, loss: 424.636\n",
      "Epoch 99, loss: 436.824\n",
      "Epoch 100, loss: 425.086\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        # print(\"Batch: \", idx)\n",
    "        TXName, label = batch\n",
    "         # Convert the tensors to Float\n",
    "        TXName = TXName.to(\"cuda\")\n",
    "        label = label.float().to(\"cuda\")\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform feedforward calculations and get the output\n",
    "        output = model(TXName)\n",
    "\n",
    "        # Define the target coordinates\n",
    "        target = label\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Perform backpropagation and update the parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    print(\"Epoch %d, loss: %.3f\" % (epoch + 1, running_loss / len(dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tx_name_ids = torch.tensor(tokenizer.encode(\"TX_MainEntrence_Right--------- TX_F1_Fountain---------------- TX_F1_Instrument_4------------ TX_F1_Instrument_5------------ TX_F1_Instrument_6------------ TX_F1_Fountain2--------------- TX_F1_Fountain3--------------- ------------------------------ ------------------------------ ------------------------------\", padding='max_length', max_length=1024, add_special_tokens=True)).unsqueeze(0).to(\"cuda\")\n",
    "    output = model(tx_name_ids)\n",
    "    print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
